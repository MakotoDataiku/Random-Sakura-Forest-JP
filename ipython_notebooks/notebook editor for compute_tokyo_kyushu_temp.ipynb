{
  "metadata": {
    "creator": "mmiyazaki",
    "customFields": {},
    "kernelspec": {
      "display_name": "Python (env ebay-scraping)",
      "language": "python",
      "name": "py-dku-venv-ebay-scraping"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "tags": [
      "deleted-recipe-editor"
    ]
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 143,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import dataiku\n",
        "import pandas as pd, numpy as np\n",
        "from dataiku import pandasutils as pdu\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv"
      ],
      "outputs": []
    },
    {
      "execution_count": 144,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "place_code \u003d {\"東京\":{\"prec_no\":\"44\", \"block_no\":\"47662\", \"type\":\"s1\"}, \"大分\":{\"prec_no\":\"83\", \"block_no\":\"0808\", \"type\":\"a1\"}, \"弘前\":{\"prec_no\":\"31\", \"block_no\":\"0166\", \"type\":\"a1\"}}\n",
        "base_url \u003d \"http://www.data.jma.go.jp/obd/stats/etrn/view/daily_%s.php?prec_no\u003d%s\u0026block_no\u003d%s\u0026year\u003d%s\u0026month\u003d%s\u0026day\u003d\u0026view\u003dp1\"\n",
        "\n",
        "# base_url \u003d \"http://www.data.jma.go.jp/obd/stats/etrn/view/daily_a1.php?prec_no\u003d83\u0026block_no\u003d0933\u0026year\u003d2011\u0026month\u003d12\u0026day\u003d\u0026view\u003dp1\"\n",
        "\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 145,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#取ったデータをfloat型に変えるやつ。(データが取れなかったとき気象庁は\"/\"を埋め込んでいるから0に変える)\n",
        "def str2float(str):\n",
        "    try:\n",
        "        return float(str)\n",
        "    except:\n",
        "        return 0.0"
      ],
      "outputs": []
    },
    {
      "execution_count": 146,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "l \u003d []\n",
        "#都市を網羅します\n",
        "for place in place_code.keys():\n",
        "    #最終的にデータを集めるリスト (下に書いてある初期値は一行目。つまり、ヘッダー。)\n",
        "    print(place)\n",
        "    # index \u003d place_name.index(place)\n",
        "    prec_no \u003d place_code[place][\"prec_no\"]\n",
        "    block_no \u003d place_code[place][\"block_no\"]\n",
        "    data_type \u003d place_code[place][\"type\"]\n",
        "    \n",
        "    # for文で2007年~2017年までの11回。\n",
        "    for year in range(1991, 2021):\n",
        "        print(year)\n",
        "        # その年の1月~12月の12回を網羅する。\n",
        "        for month in range(1,13):\n",
        "            #print(month)\n",
        "            #2つの都市コードと年と月を当てはめる。\n",
        "            r \u003d requests.get(base_url%(data_type, prec_no, block_no, year, month))\n",
        "            r.encoding \u003d r.apparent_encoding\n",
        "\n",
        "            # まずはサイトごとスクレイピング\n",
        "            soup \u003d BeautifulSoup(r.text)\n",
        "            # findAllで条件に一致するものをすべて抜き出します。\n",
        "            # 今回の条件はtrタグでclassがmtxになってるものです。\n",
        "            rows \u003d soup.findAll(\u0027tr\u0027,class_\u003d\u0027mtx\u0027)\n",
        "\n",
        "            # 表の最初の1~4行目はカラム情報なのでスライスする。(indexだから初めは0だよ)\n",
        "            # 【追記】2020/3/11 申し訳ございません。間違えてました。\n",
        "            if data_type \u003d\u003d \"a1\":\n",
        "                rows_data \u003d rows[3:]\n",
        "\n",
        "                # 1日〜最終日までの１行を網羅し、取得します。\n",
        "                for row in rows_data:\n",
        "                    # 今度はtrのなかのtdをすべて抜き出します\n",
        "                    data \u003d row.findAll(\u0027td\u0027)\n",
        "\n",
        "                    #１行の中には様々なデータがあるので全部取り出す。\n",
        "                    # ★ポイント\n",
        "                    day \u003d data[0].findAll(\u0027a\u0027)[0].string # 日にち\n",
        "                    date \u003d str(year) + \"/\" + str(month) + \"/\" + day\n",
        "                    precip_total  \u003d data[1].string #降水量(mm)合計\n",
        "                    temp_ave \u003d data[4].string #平均気温\n",
        "                    temp_high \u003d data[5].string #最高気温\n",
        "                    temp_low \u003d data[6].string #最低気温\n",
        "                    daylight \u003d data[13].string #日照時間\n",
        "                    d \u003d {\"date\":date, \"precip_total\":precip_total, \"temp_ave\":temp_ave, \"temp_high\":temp_high, \"temp_low\":temp_low, \"daylight\":daylight, \"place\":place}\n",
        "                    l.append(d)\n",
        "            else:\n",
        "                rows_data \u003d rows[4:]\n",
        "                for row in rows_data:\n",
        "                    # 今度はtrのなかのtdをすべて抜き出します\n",
        "                    data \u003d row.findAll(\u0027td\u0027)\n",
        "\n",
        "                    #１行の中には様々なデータがあるので全部取り出す。\n",
        "                    # ★ポイント\n",
        "                    day \u003d data[0].findAll(\u0027a\u0027)[0].string\n",
        "                    date \u003d str(year) + \"/\" + str(month) + \"/\" + day\n",
        "                    precip_total  \u003d data[3].string #降水量(mm)合計\n",
        "                    temp_ave \u003d data[6].string #平均気温\n",
        "                    temp_high \u003d data[7].string #最高気温\n",
        "                    temp_low \u003d data[8].string #最低気温\n",
        "                    daylight \u003d data[16].string #日照時間\n",
        "                    d \u003d {\"date\":date, \"precip_total\":precip_total, \"temp_ave\":temp_ave, \"temp_high\":temp_high, \"temp_low\":temp_low, \"daylight\":daylight, \"place\":place}\n",
        "                    l.append(d)\n",
        "                    \n",
        "df \u003d pd.DataFrame(l)"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "東京\n",
            "1991\n",
            "1992\n",
            "1993\n",
            "1994\n",
            "1995\n",
            "1996\n",
            "1997\n",
            "1998\n",
            "1999\n",
            "2000\n",
            "2001\n",
            "2002\n",
            "2003\n",
            "2004\n",
            "2005\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "2009\n",
            "2010\n",
            "2011\n",
            "2012\n",
            "2013\n",
            "2014\n",
            "2015\n",
            "2016\n",
            "2017\n",
            "2018\n",
            "2019\n",
            "2020\n",
            "大分\n",
            "1991\n",
            "1992\n",
            "1993\n",
            "1994\n",
            "1995\n",
            "1996\n",
            "1997\n",
            "1998\n",
            "1999\n",
            "2000\n",
            "2001\n",
            "2002\n",
            "2003\n",
            "2004\n",
            "2005\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "2009\n",
            "2010\n",
            "2011\n",
            "2012\n",
            "2013\n",
            "2014\n",
            "2015\n",
            "2016\n",
            "2017\n",
            "2018\n",
            "2019\n",
            "2020\n",
            "弘前\n",
            "1991\n",
            "1992\n",
            "1993\n",
            "1994\n",
            "1995\n",
            "1996\n",
            "1997\n",
            "1998\n",
            "1999\n",
            "2000\n",
            "2001\n",
            "2002\n",
            "2003\n",
            "2004\n",
            "2005\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "2009\n",
            "2010\n",
            "2011\n",
            "2012\n",
            "2013\n",
            "2014\n",
            "2015\n",
            "2016\n",
            "2017\n",
            "2018\n",
            "2019\n",
            "2020\n"
          ]
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write recipe outputs\n",
        "tokyo_kyushu_temp \u003d dataiku.Dataset(\"tokyo_kyushu_temp\")\n",
        "tokyo_kyushu_temp.write_with_schema(df)"
      ],
      "outputs": []
    }
  ]
}